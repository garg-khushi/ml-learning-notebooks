{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68aa22e8-e3e6-419c-b7e7-eb27a143841f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.0.5-py3-none-macosx_12_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.13/site-packages (from xgboost) (2.1.3)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.13/site-packages (from xgboost) (1.15.3)\n",
      "Downloading xgboost-3.0.5-py3-none-macosx_12_0_arm64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.0.5\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11fdd76e-92ef-469b-b9bd-79528b1b4f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load california housing dataset\n",
    "data=fetch_california_housing()\n",
    "X,y=data.data, data.target\n",
    "#split data into training and test sets\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38bc8ba8-b474-496a-a2e5-a3733255e239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Observations: 20640\n",
      "Number of Features: 8\n"
     ]
    }
   ],
   "source": [
    "#observations and features in dataset\n",
    "N_observations, N_features= X.shape\n",
    "print('Number of Observations: ' + str(N_observations))\n",
    "print('Number of Features: ' + str(N_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92bd1a0e-9d98-4138-8c9d-22c63c41090d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/xgboost/core.py:726: FutureWarning: Pass `objective` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#initialise models\n",
    "#define estimators, indiv treees\n",
    "n_estimators=100\n",
    "rf=RandomForestRegressor(n_estimators=n_estimators, random_state=42)\n",
    "xgb=XGBRegressor(n_estimators, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56db276-8cfe-494a-96db-ff8f567cc290",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit model\n",
    "#measure training time for random forest\n",
    "start_time_rf=time.time()\n",
    "rf.fit(X_train, y_train)\n",
    "end_time_rf=time.time()\n",
    "rf_train_tie=end_time_rf- start_time_rf\n",
    "start_time_xgb = time.time()\n",
    "xgb.fit(X_train, y_train)\n",
    "end_time_xgb = time.time()\n",
    "xgb_train_time = end_time_xgb - start_time_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3256b83-d388-4f87-9294-29fab11b5aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, import necessary libraries (if not already imported)\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestRegressor  # Changed to Regressor for continuous target\n",
    "import xgboost as xgb\n",
    "\n",
    "# Create the models\n",
    "# Changed to regression models since the target appears to be continuous\n",
    "rf = RandomForestRegressor()  # Changed from RandomForestClassifier\n",
    "xgb_model = xgb.XGBRegressor()  # Changed from XGBClassifier\n",
    "\n",
    "# Fit the models on training data\n",
    "# Assuming X_train and y_train are already defined\n",
    "rf.fit(X_train, y_train)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Using fitted models to make predictions on testset\n",
    "# Measure prediction time for Random Forest\n",
    "start_time_rf = time.time()\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "end_time_rf = time.time()\n",
    "rf_pred_time = end_time_rf - start_time_rf\n",
    "\n",
    "# Measure prediction time for XGBoost\n",
    "start_time_xgb = time.time()\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "end_time_xgb = time.time()\n",
    "xgb_pred_time = end_time_xgb - start_time_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f491b3-bdb1-4132-8159-f5826ec30aae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb654ca9-54ce-4b87-acfa-e11a706748c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
